#!/usr/bin/env python3
"""Test direct Ollama connection and model functionality"""

import requests
import json

def test_ollama_direct():
    """Test direct connection to Ollama"""
    print("ğŸ” Testing Direct Ollama Connection...")
    
    # Test basic connection
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            models = response.json()
            print(f"âœ… Ollama connected, found {len(models['models'])} models")
            for model in models['models'][:3]:  # Show first 3
                print(f"   - {model['name']}")
        else:
            print(f"âŒ Ollama connection failed: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Ollama connection error: {e}")
        return False
    
    # Test model generation
    try:
        test_prompt = "Hello, please respond with exactly 'Test successful' if you can understand me."
        payload = {
            "model": "phi4:latest",
            "prompt": test_prompt,
            "stream": False
        }
        
        response = requests.post("http://localhost:11434/api/generate", json=payload)
        if response.status_code == 200:
            result = response.json()
            response_text = result.get('response', '').strip()
            print(f"âœ… Model test response: {response_text[:100]}...")
            return True
        else:
            print(f"âŒ Model generation failed: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Model generation error: {e}")
        return False

def test_openai_compat():
    """Test OpenAI-compatible endpoint"""
    print("\nğŸ” Testing OpenAI-Compatible API...")
    
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer dummy"  # Ollama doesn't need real auth
        }
        
        payload = {
            "model": "phi4:latest",
            "messages": [
                {"role": "user", "content": "Say 'OpenAI compatibility test successful' if you understand."}
            ],
            "max_tokens": 50
        }
        
        response = requests.post("http://localhost:11434/v1/chat/completions", 
                               json=payload, headers=headers)
        
        if response.status_code == 200:
            result = response.json()
            message = result['choices'][0]['message']['content']
            print(f"âœ… OpenAI API test: {message}")
            return True
        else:
            print(f"âŒ OpenAI API failed: {response.status_code}")
            print(f"Response: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ OpenAI API error: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ Testing Ollama Functionality\n")
    
    direct_ok = test_ollama_direct()
    openai_ok = test_openai_compat()
    
    print(f"\nğŸ“Š Results:")
    print(f"Direct API: {'âœ… PASS' if direct_ok else 'âŒ FAIL'}")
    print(f"OpenAI API: {'âœ… PASS' if openai_ok else 'âŒ FAIL'}")
    
    if direct_ok and openai_ok:
        print("ğŸ‰ Ollama is fully functional!")
    else:
        print("âš ï¸ Some Ollama features need attention")
